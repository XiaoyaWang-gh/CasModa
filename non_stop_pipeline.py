# for RQ2 (non-stop v.s. casceded)
import os
import sys
import time
import json
import logging

from dotenv import load_dotenv
from typing import List

from CUTE_components.models import Testcase_datapoint, Test_Unit_Status, Result_datapoint
from CUTE_components.dataset import Testcase_Dataset
from prompt.prompt_testbody_query import TestcasePrompt
from CUTE_pipeline import clear_chat_history, call_chatgpt, compile_mytest, execute_mytest, repair_bf, repair_tf_test_unit
from util.strUtils import form_complete_statement, fetch_method_chatgpt_out
from util.use_unixcoder import testcase_diversity_retriever
from util.utils import write_to_file


ID_PLACEHOLDER = "<ID>"
TM_PLACEHOLDER = "<TestMethodPlaceHolder>"

message_list = [
    {"role": "system", "content": "You are a proficient and helpful assistant in java testing with JUnit4 and Mockito frameworks."}
]


def get_testbody_prompt(demos: List[Testcase_datapoint], query: Testcase_datapoint) -> str:
    '''
    æ„é€ few-shot learningçš„prompt
    queryå’Œdemoçš„å·®åˆ«åœ¨äºqueryçš„test_bodyä¸ºç©ºå­—ç¬¦ä¸²
    '''
    prompt = TestcasePrompt(demos, query)
    return prompt.construct_prompt()


def main():
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    # args = sys.argv
    # if len(args) != 3:
    #     print("Usage: python -m  non_stop_pipeline <project_name> <start_idx>")
    #     exit(1)
    # else:
    #     pro = args[1]
    #     start_idx = int(args[2])

    pro = 'binance'
    start_idx = 237

    # å‡†å¤‡æ•°æ®è·¯å¾„
    queryset_dir_path = f"txt_repo/testbody/query_set/{pro}"
    demopool_dir_path = f"txt_repo/testbody/demo_pool/{pro}"

    testunit_compile_stderr_dir_path = f"txt_repo/validation/{pro}/output/nonstop/testunit_compile"
    testunit_execute_stdout_dir_path = f"txt_repo/validation/{pro}/output/nonstop/testunit_execute"

    id_to_num_file = f"txt_repo/validation/{pro}/id_to_num.txt"
    overall_result_file = f"txt_repo/validation/{pro}/output/nonstop/overall_result.txt"
    passed_unit_file = f"txt_repo/validation/{pro}/output/nonstop/passed_test_unit.txt"
    check_chatgpt_file = f"txt_repo/validation/{pro}/output/nonstop/check_chatgpt.txt"
    compile_suc_and_execute_fail = f"txt_repo/validation/{pro}/output/nonstop/compile_suc_and_execute_fail_case.txt"

    # è®¾ç½®ä¸€ä¸ªloggerï¼Œå–ä»£å¯¼å‡ºæ•£è½çš„print
    logger = logging.getLogger(__name__)
    logger.setLevel(level=logging.INFO)
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    load_dotenv()
    # è¯»å–ç¯å¢ƒå˜é‡
    querynum_dict_str = os.getenv("QUERYNUM_DICT")
    querynum_dict = json.loads(querynum_dict_str)
    testunit_compile_num = int(os.getenv("TESTUNIT_COMPILE_NUM"))
    testunit_execute_num = int(os.getenv("TESTUNIT_EXECUTE_NUM"))
    chatgpt_max_num = int(os.getenv("CHATGPT_MAX_NUM"))
    shot_num = int(os.getenv("SHOT_NUM"))

    # è¯»å–queryset
    queryset = Testcase_Dataset(
        queryset_dir_path,
        "classname.txt",
        "constr_sign.txt",
        "focalname_paralist.txt",
        "test_name.txt",
        "fake_test_body.txt",
        "unixcoder_tensor.txt"
    )

    queryset_list = queryset.parse()
    assert len(queryset_list) == querynum_dict[pro]

    demopool = Testcase_Dataset(
        demopool_dir_path,
        "classname.txt",
        "constr_sign.txt",
        "focalname_paralist.txt",
        "test_name.txt",
        "test_body.txt",
        "unixcoder_tensor.txt"
    )

    try:
        result_datapoint_list = []
        # è¿›å…¥å¾ªç¯
        end_idx = len(queryset_list)  # len(queryset_list)
        for id in range(start_idx, end_idx+1, 1):  #
            logger.info(f"ğŸ’«æ¥åˆ°ç¬¬{id}ä¸ªè¾“å…¥ğŸ’«")

            result_datapoint = Result_datapoint(
                id, 0, 0, Test_Unit_Status.NONE_STATUS)
            tmp_query = queryset_list[id-1]

            tmp_demopool_list = demopool.parse(
                tmp_query.classname+tmp_query.focalname_paralist)

            candidate_demos, _ = testcase_diversity_retriever(
                tmp_query, tmp_demopool_list, shot_num)

            # generation stage
            logger.info('-'*10+" "+"generation stage"+" "+'-'*10)

            clear_chat_history()  # å½“å‰queryçš„é¦–æ¬¡è°ƒç”¨ï¼Œè‡ªç„¶æ¸…ç©ºä¸Šä¸€æ¬¡çš„èŠå¤©è®°å½•

            return_testcase = ""
            prompt_for_gen = get_testbody_prompt(
                candidate_demos, tmp_query)

            for i in range(1, chatgpt_max_num, 1):  # retryå¤–åŒ…çŠ¶æ€ç çš„é—®é¢˜ï¼Œè¿™é‡Œè§£å†³ç©ºå€¼å’Œä¸å«ä»£ç çš„é—®é¢˜
                write_to_file(check_chatgpt_file,
                              f"generation stage ç¬¬{i}æ¬¡è°ƒç”¨chatgpt\n")
                return_testcase = call_chatgpt(prompt_for_gen)
                if return_testcase != "":  # å¦‚æœè°ƒç”¨è¿”å›æ­£å¸¸ï¼Œå°±è·³å‡ºå¾ªç¯
                    break
            return_testcase = fetch_method_chatgpt_out(return_testcase)
            return_testcase = form_complete_statement(return_testcase)
            write_to_file(check_chatgpt_file,
                          f"ç”Ÿæˆçš„testcaseä¸ºï¼š{return_testcase}  \n"+'-'*100 + '\n')

            test_unit = "public void " + \
                tmp_query.test_name + "{\n" + return_testcase + "\n}"

            write_to_file(check_chatgpt_file,
                          f"å¾—åˆ°çš„test methodä¸ºï¼š\n{test_unit}  \n"+'-'*100 + '\n')

            # feedback stage
            logger.info('-'*10+" "+"feedback stage"+" "+'-'*10)
            clear_chat_history()  # ä¿®å¤test_unitçš„ç¼–è¯‘é”™è¯¯ ç¬¬2ä¸ªæ¸…ç©ºèŠå¤©è®°å½•èŠ‚ç‚¹
            compile_success = False
            for turn in range(1, testunit_compile_num+1, 1):
                compile_res, compile_out = compile_mytest(
                    pro, test_unit, id, testunit_compile_stderr_dir_path)
                result_datapoint.test_unit_compile_time += 1
                if compile_res:
                    logger.info(f"test unit åœ¨ç¬¬{turn}è½®ç¼–è¯‘æˆåŠŸ")
                    compile_success = True
                    break
                else:
                    if turn != testunit_compile_num:  # è‡³å¤šä¿®å¤testunit_compile_num-1æ¬¡
                        logger.info(f"test unit åœ¨ç¬¬{turn}è½®ç¼–è¯‘å¤±è´¥ï¼Œè¿›è¡Œä¿®å¤")
                        test_unit = repair_bf(
                            test_unit, compile_out, tmp_query, chatgpt_max_num)  # è¿™é‡Œä¸å¯¹ï¼Œç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯Prefix_datapointï¼Œä¸æ˜¯Oracle_datapoint, åº”æƒ³åŠæ³•è§£å†³ï¼Œæˆ–è€…å¹²è„†ä¼ å…¥Prefix_datapoint?
                        write_to_file(
                            check_chatgpt_file, f"å®Œæˆç¬¬{turn}æ¬¡ä¿®å¤ï¼Œä¿®å¤åçš„test_unitä¸ºï¼š\n{test_unit}\n" + '-'*100 + '\n')
            if not compile_success:
                logger.info(f"test unit {testunit_compile_num}æ¬¡ç¼–è¯‘å‡å¤±è´¥ï¼Œæ”¾å¼ƒè¿™ä¸€æ¬¡çš„ç”Ÿæˆ")
                result_datapoint.test_unit_status = Test_Unit_Status.NOT_COMPILE_SUCCESS
                
                result_datapoint_list.append(result_datapoint)
                continue

            clear_chat_history()  # ä¿®å¤test_unitçš„æ‰§è¡Œé”™è¯¯ ç¬¬3ä¸ª(also the last one)æ¸…ç©ºèŠå¤©è®°å½•èŠ‚ç‚¹
            execute_success = False
            for cycle in range(1, testunit_execute_num+1, 1):
                execute_res, execute_out = execute_mytest(
                    pro, test_unit, id, testunit_execute_stdout_dir_path)
                result_datapoint.test_unit_execute_time += 1
                if execute_res:
                    logger.info(f"test unit åœ¨ç¬¬{cycle}è½®æ‰§è¡ŒæˆåŠŸ")
                    execute_success = True
                    break
                else:
                    if cycle != testunit_execute_num:  # è‡³å¤šä¿®å¤testunit_execute_num-1æ¬¡
                        logger.info(f"test unit åœ¨ç¬¬{cycle}è½®æ‰§è¡Œå¤±è´¥ï¼Œè¿›è¡Œä¿®å¤")
                        test_unit = repair_tf_test_unit(
                            test_unit, execute_out, tmp_query, chatgpt_max_num)
                        write_to_file(
                            check_chatgpt_file, f"å®Œæˆç¬¬{cycle}æ¬¡ä¿®å¤ï¼Œä¿®å¤åçš„test_unitä¸ºï¼š\n{test_unit}\n"+'-'*100 + '\n')
            if not execute_success:
                logger.info(f"test unit {testunit_execute_num}æ¬¡æ‰§è¡Œå‡å¤±è´¥ï¼Œæ”¾å¼ƒè¿™ä¸€æ¬¡çš„ç”Ÿæˆ")
                logger.info(f"æœ€ç»ˆæ²¡èƒ½ç”Ÿæˆå¯æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹"+'\n'+'-'*100+'\n')
                result_datapoint.test_unit_status = Test_Unit_Status.COMPILE_SUCCESS_BUT_NOT_EXECUTE
                result_datapoint.compile_suc_execute_fail_unit = test_unit
            else:
                print(f"æµ‹è¯•é€šè¿‡~~~"+'\n'+'-'*100+'\n')
                test_unit = test_unit.replace("\n", " ")
                result_datapoint.passed_test_unit = test_unit
                logger.info(
                    f"result_datapoint : {result_datapoint.toString()}")
                result_datapoint.test_unit_status = Test_Unit_Status.EXECUTE_SUCCESS
            result_datapoint_list.append(result_datapoint)

    except Exception as e:
        logger.info(f"main method got an exception: {e}")
    finally:
        for result_datapoint in result_datapoint_list:
            write_to_file(overall_result_file, result_datapoint.toString())

        # ç°åœ¨æ˜¯éœ€è¦å¡«è®ºæ–‡è¡¨æ ¼çš„ç»“æœ
        with open(id_to_num_file, "r") as f:
            id_to_num_list = f.readlines()
        bf_num, tf_num, passed_num = 0, 0, 0
        for result_datapoint in result_datapoint_list:
            now_id = result_datapoint.id
            status = result_datapoint.test_unit_status
            times = int(id_to_num_list[now_id-1])
            if status == Test_Unit_Status.NOT_COMPILE_SUCCESS:
                bf_num += times
            elif status == Test_Unit_Status.COMPILE_SUCCESS_BUT_NOT_EXECUTE:
                tf_num += times
                write_to_file(compile_suc_and_execute_fail,
                              str(result_datapoint.id)+", "+result_datapoint.compile_suc_execute_fail_unit+"\n")
            elif status == Test_Unit_Status.EXECUTE_SUCCESS:
                passed_num += times
                write_to_file(passed_unit_file,
                              str(result_datapoint.id)+", "+result_datapoint.passed_test_unit+"\n")
            else:
                raise Exception("å‡ºç°äº†ä¸åº”è¯¥å‡ºç°çš„ç»“æœçŠ¶æ€")

        # æœ€åæŠŠæ•´ä½“çš„æƒ…å†µå†™å…¥åˆ°overall_outputä¸­
        # æ‰“å°æ•´ä¸ªé¡¹ç›®çš„è¿è¡Œç»“æœ
        total_num = bf_num + tf_num + passed_num

        # è¾“å‡ºæ¯ç§ç±»å‹çš„ç»å¯¹æ•°é‡å’Œæ‰€å æ¯”ä¾‹
        percentage = (bf_num / total_num) * 100
        write_to_file(overall_result_file,
                      f"\n\nbuild failed : {bf_num} ({percentage:.2f}%) \n")
        percentage = (tf_num / total_num) * 100
        write_to_file(overall_result_file,
                      f"test failed : {tf_num} ({percentage:.2f}%) \n")
        percentage = (passed_num / total_num) * 100
        write_to_file(overall_result_file,
                      f"passed : {passed_num} ({percentage:.2f}%) \n")


if __name__ == "__main__":
    start_time = time.time()
    main()
    end_time = time.time()
    elapsed_time = end_time - start_time
    minutes = int(elapsed_time // 60)
    seconds = int(elapsed_time % 60)
    print(f"æ€»è€—æ—¶: {minutes} min {seconds} sec")
